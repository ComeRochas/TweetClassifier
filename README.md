# TweetClassifier â€” Multimodal Twitter Classifier

Projet: Classificateur multimodal (texte + mÃ©tadonnÃ©es) pour tweets basÃ© sur PyTorch et HuggingFace.

## ğŸŒŸ RÃ©sumÃ©
Ce dÃ©pÃ´t contient une implÃ©mentation d'un classificateur multimodal pour des tweets qui combine:
- Un encodeur Transformer (XLM-RoBERTa) sur le texte
- Un MLP lÃ©ger sur 8 features numÃ©riques (mÃ©tadonnÃ©es d'utilisateur)
- Une couche de fusion qui concatÃ¨ne l'embedding CLS du transformer et la sortie du MLP

Le but est de produire une prÃ©diction binaire (0/1).

## ğŸ“ Structure du projet
- `dataset.py` : Dataset PyTorch (tokenization + conversion metadata -> tensors).
- `model.py` : `MultimodalTweetClassifier` (Transformer + metadata MLP + classifier)
- `train_multimodal.py` : Script d'entraÃ®nement avec validation et sauvegarde du meilleur modÃ¨le
- `predict_kaggle.py` : Script de prÃ©diction pour `kaggle_test.jsonl` (sauvegarde `multimodal_transformer.csv`)
- `config.py` : Dataclass `TrainingConfig` pour centraliser les hyperparamÃ¨tres
- `baseline.ipynb` : Notebook d'exploration et prÃ©traitement

> Les fichiers de donnÃ©es (`train.jsonl`, `kaggle_test.jsonl`) et les modÃ¨les entraÃ®nÃ©s (`best_multimodal_model.pt`, `scaler.pkl`) **ne sont pas** inclus dans le dÃ©pÃ´t (voir `.gitignore`).

## âš™ï¸ PrÃ©requis
- Python 3.8+ (ou 3.10/3.11 selon votre environnement)
- RecommandÃ©: GPU CUDA ou MPS (Mac)

Installer les dÃ©pendances :

```bash
# CrÃ©ez un environnement virtuel (optionnel mais recommandÃ©)
python3 -m venv venv
source venv/bin/activate
# Installer les dÃ©pendances (voir requirements.txt)
pip install -r requirements.txt
```

## ğŸ”§ Installation (rapide)
```bash
# Si vous n'avez pas encore clonÃ© le repo
git clone https://github.com/ComeRochas/TweetClassifier.git
cd TweetClassifier
python3 -m venv venv
source venv/bin/activate
pip install -r requirements.txt
```

## ğŸš€ EntraÃ®nement
Le script `train_multimodal.py` inclut la tokenization, la normalisation des mÃ©tadonnÃ©es, la sÃ©paration train/val, et le training.

Exemple d'entraÃ®nement (rapide):

```bash
python3 train_multimodal.py --num_epochs 1 --batch_size 8
```

Options utiles (CLI)
- `--batch_size` : taille de batch (par dÃ©faut 16)
- `--num_epochs` : nombre d'Ã©poques (par dÃ©faut 4)
- `--lr_transformer` : LR pour transformer (par dÃ©faut 2e-5)
- `--lr_head` : LR pour meta head et classifier (par dÃ©faut 1e-3)
- `--max_length` : longueur max des tokens (par dÃ©faut 160)
- `--freeze_transformer` : gÃ¨le le transformer (ne l'entraÃ®ne pas)

Exemple avec freeze:

```bash
python3 train_multimodal.py --freeze_transformer --num_epochs 3
```

> Astuce : commencez par geler le transformer (`--freeze_transformer`) pour valider la boucle d'entraÃ®nement rapidement, puis dÃ©bloquez-le pour fine-tuning si besoin.

## ğŸ§ª PrÃ©diction / Soumission Kaggle
Une fois le modÃ¨le entraÃ®nÃ© (`best_multimodal_model.pt`), le script `predict_kaggle.py`:

- Charge le scaler (scaler.pkl)
- Tokenize + scale les features
- PrÃ©pare un fichier `multimodal_transformer.csv` avec deux colonnes : `ID`, `Prediction`

Exemple:

```bash
python3 predict_kaggle.py
```

## ğŸ“Œ Notes sur les hyperparamÃ¨tres
- Le fichier `config.py` contient `TrainingConfig` qui regroupe les hyperparamÃ¨tres par dÃ©faut.
- On diffÃ©rencie les LR des paramÃ¨tres du transformer (petit) et du head (plus haut).
- Par dÃ©faut `max_length` est 160 â€” les stats sur vos tweets montrent un mÃ©dian â‰ˆ 55, mean â‰ˆ 58, 99e percentile â‰ˆ 127, ainsi 160 est conservateur (Ã©vite la troncature pour la plupart).

## ğŸ—‚ï¸ DonnÃ©es
Le format attendu par les scripts :
- `train.jsonl` : JSON Lines, chaque ligne contient un tweet, avec des champs user.* et Ã©ventuellement `label`: 0 / 1
- `kaggle_test.jsonl` : similaire mais sans `label`; contient `challenge_id` pour la soumission

> Les Ã©tapes d'extraction / scaling sont dÃ©jÃ  implÃ©mentÃ©es dans `train_multimodal.py` et `predict_kaggle.py`.

## ğŸ” ReproductibilitÃ©
- Les seeds sont fixÃ©es via `cfg.seed` depuis `config.py`

## ğŸ› ï¸ DÃ©veloppement & contributions
- Ajoutez des issues / PR si vous souhaitez amÃ©liorer les datasets, features, ou le modÃ¨le (ex: combiner un finetuning progressif, scheduler, etc.)

## ğŸ“œ Licence
- Ajoutez la licence si vous voulez rendre le projet public; actuellement pas de licence dÃ©finie.

---

Si vous voulez, je peux :
- Ajouter un `README` en anglais en plus
- CrÃ©er un `requirements.txt` (je l'ai dÃ©jÃ  ajoutÃ©) et l'installer automatiquement
- Ajouter une action GitHub CI pour tests/format
- Ajouter un `Makefile` ou un wrapper `run.sh`

N'hÃ©sitez pas Ã  me dire ce que vous prÃ©fÃ©rez !
